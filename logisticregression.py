# -*- coding: utf-8 -*-
"""LogisticRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YIgEpbUioNcj74tbHiMwCdL3VyDPtoOI

## 1. Logistic Regression in Python With scikit-learn: Example 1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#Giving the length of tumer predicting the pobability that its a cancerous
x=np.array([3.78, 2.44, 2.09, 0.14, 1.72, 1.65, 4.92, 4.37, 4.96, 4.52, 3.69, 5.88]).reshape((-1,1))
y=np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])
print("x=",x)
print("y=",y)

plt.scatter(x,y)
plt.xlabel("IV")
plt.ylabel("DV")
plt.show()

from sklearn.linear_model import LogisticRegression

LR1=LogisticRegression()

LR1.fit(x,y)

predicted=LR1.predict(np.array([3.44]).reshape((-1,1)))
print(predicted)

log_coef=LR1.coef_
odds=np.exp(log_coef)
print(odds)#This tells us that as the size of a tumor increases by 1mm the odds of it being a cancerous tumor increases by 4x.

def logit2prob():
  log_odds = LR1.coef_ * x + LR1.intercept_
  odds = np.exp(log_odds)
  probability = odds / (1 + odds)
  return(probability)

prob=logit2prob()
print("probability:",prob)
y_pred=LR1.predict(x)
print("y_predict=:",y_pred)

# Plot the sigmoid curve
x_range = np.linspace(np.min(x), np.max(x), 100).reshape(-1, 1)
probabilities = LR1.predict_proba(x_range)[:, 1]  # Probability of class 1

plt.plot(x_range, probabilities, color='red', label='Sigmoid Curve')
plt.scatter(x,y_pred,color='Black',marker='*',label='Data Points')

plt.legend()
plt.grid()
plt.title('Sigmoid Curve for Logistic Regression')
plt.show()

